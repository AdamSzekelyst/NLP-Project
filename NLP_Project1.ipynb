{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZPFNjSJ_qIt",
        "outputId": "2ec0af20-4787-4e6c-e997-a7aa133eaab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.49      0.33      0.39       752\n",
            "    Positive       0.52      0.68      0.59       804\n",
            "\n",
            "    accuracy                           0.51      1556\n",
            "   macro avg       0.51      0.50      0.49      1556\n",
            "weighted avg       0.51      0.51      0.49      1556\n",
            "\n",
            "Model: SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.66      0.46      0.55       752\n",
            "    Positive       0.61      0.78      0.68       804\n",
            "\n",
            "    accuracy                           0.63      1556\n",
            "   macro avg       0.64      0.62      0.61      1556\n",
            "weighted avg       0.63      0.63      0.62      1556\n",
            "\n",
            "Model: Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.62      0.53      0.57       752\n",
            "    Positive       0.61      0.70      0.65       804\n",
            "\n",
            "    accuracy                           0.62      1556\n",
            "   macro avg       0.62      0.61      0.61      1556\n",
            "weighted avg       0.62      0.62      0.61      1556\n",
            "\n",
            "Sentiment prediction for 'Bitcoin is going to the moon!': ['Positive']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Adatok letöltése\n",
        "# A különböző adatfájlok elérési útjainak meghatározása\n",
        "splits = {\n",
        "    'train': 'data/train-00000-of-00001-cc8461398e266567.parquet',\n",
        "    'test': 'data/test-00000-of-00001-922aa10406034550.parquet',\n",
        "    'eval': 'data/eval-00000-of-00001-dc793d916ae447cb.parquet'\n",
        "}\n",
        "\n",
        "# A tanító adatok betöltése a megadott elérési útvonalról\n",
        "df = pd.read_parquet(\"hf://datasets/ckandemir/bitcoin_tweets_sentiment_kaggle/\" + splits[\"train\"])\n",
        "\n",
        "# Mintavétel az adatokból (például 10%)\n",
        "# Csak a teljes adatkészlet 10%-át használjuk a gyorsabb futás érdekében\n",
        "df_sample = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Az adatok első néhány sorának megtekintése\n",
        "df_sample.head()\n",
        "\n",
        "# Szövegek előkészítése és tisztítása\n",
        "# A szövegek tisztítására szolgáló függvény definiálása\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # URL-ek eltávolítása\n",
        "    text = re.sub(r'@\\w+', '', text)  # Felhasználónevek eltávolítása\n",
        "    text = re.sub(r'#\\w+', '', text)  # Hashtagek eltávolítása\n",
        "    text = re.sub(r'\\d+', '', text)  # Számok eltávolítása\n",
        "    text = text.lower()  # Kisbetűsítés\n",
        "    return text\n",
        "\n",
        "# A tisztító függvény alkalmazása az adatokra\n",
        "df_sample['cleaned_text'] = df_sample['text'].apply(clean_text)\n",
        "\n",
        "# Adatok szétválasztása tanító és teszt adatokra\n",
        "# Az adatok 80%-át tanító, 20%-át teszt adatokra osztjuk\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_sample['cleaned_text'], df_sample['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Szövegek vektorizálása\n",
        "# A TF-IDF vektorizáló inicializálása, amely legfeljebb 5000 jellemzőt használ\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "# A tanító adatok vektorizálása\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "# A teszt adatok vektorizálása\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Több modell összeállítása\n",
        "# Különböző gépi tanulási modellek definiálása\n",
        "models = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'SVM': SVC(),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "# Modellek kipróbálása és kiértékelése\n",
        "# Minden modell betanítása és kiértékelése\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_vec, y_train)  # Modell betanítása\n",
        "    y_pred = model.predict(X_test_vec)  # Előrejelzések készítése a teszt adatokra\n",
        "    print(f\"Model: {model_name}\")  # Modell neve\n",
        "    print(classification_report(y_test, y_pred))  # Kiértékelési jelentés\n",
        "\n",
        "# Legjobb modell kiválasztása\n",
        "# (Ez a rész függ a kiértékelés eredményétől, itt csak egy példa)\n",
        "best_model = models['SVM']\n",
        "\n",
        "# Működés bemutatása\n",
        "# Függvény a szövegek osztályozására a legjobb modellel\n",
        "def predict_sentiment(text):\n",
        "    cleaned_text = clean_text(text)  # Szöveg tisztítása\n",
        "    text_vec = vectorizer.transform([cleaned_text])  # Szöveg vektorizálása\n",
        "    return best_model.predict(text_vec)  # Előrejelzés készítése\n",
        "\n",
        "# Példa használat\n",
        "example_text = \"Bitcoin is going to the moon!\"\n",
        "print(f\"Sentiment prediction for '{example_text}': {predict_sentiment(example_text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Ez ugyanaz a kód, csak egy pontosabb és jobb adathalmazzal, amit az órákon is használtunk\n",
        "\n",
        "# Adatok letöltése\n",
        "# Az IMDB adathalmaz betöltése\n",
        "imdb_dataset = pd.read_csv(\"hf://datasets/scikit-learn/imdb/IMDB Dataset.csv\")\n",
        "\n",
        "# Az adatok első néhány sorának megtekintése\n",
        "imdb_dataset.head()\n",
        "\n",
        "# Mintavétel az adatokból (például 10%)\n",
        "# Csak a teljes adatkészlet 10%-át használjuk a gyorsabb futás érdekében\n",
        "imdb_sample = imdb_dataset.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Szövegek előkészítése és tisztítása\n",
        "# A szövegek tisztítására szolgáló függvény definiálása\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # URL-ek eltávolítása\n",
        "    text = re.sub(r'@\\w+', '', text)  # Felhasználónevek eltávolítása\n",
        "    text = re.sub(r'#\\w+', '', text)  # Hashtagek eltávolítása\n",
        "    text = re.sub(r'\\d+', '', text)  # Számok eltávolítása\n",
        "    text = text.lower()  # Kisbetűsítés\n",
        "    return text\n",
        "\n",
        "# A tisztító függvény alkalmazása az adatokra\n",
        "imdb_sample['cleaned_text'] = imdb_sample['review'].apply(clean_text)\n",
        "\n",
        "# Adatok szétválasztása tanító és teszt adatokra\n",
        "# Az adatok 80%-át tanító, 20%-át teszt adatokra osztjuk\n",
        "X_train, X_test, y_train, y_test = train_test_split(imdb_sample['cleaned_text'], imdb_sample['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Szövegek vektorizálása\n",
        "# A TF-IDF vektorizáló inicializálása, amely legfeljebb 5000 jellemzőt használ\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "# A tanító adatok vektorizálása\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "# A teszt adatok vektorizálása\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Több modell összeállítása\n",
        "# Különböző gépi tanulási modellek definiálása\n",
        "models = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=100)\n",
        "}\n",
        "\n",
        "# Modellek kipróbálása és kiértékelése\n",
        "# Minden modell betanítása és kiértékelése\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_vec, y_train)  # Modell betanítása\n",
        "    y_pred = model.predict(X_test_vec)  # Előrejelzések készítése a teszt adatokra\n",
        "    print(f\"Model: {model_name}\")  # Modell neve\n",
        "    print(classification_report(y_test, y_pred))  # Kiértékelési jelentés\n",
        "\n",
        "# Legjobb modell kiválasztása\n",
        "# (Ez a rész függ a kiértékelés eredményétől, itt csak egy példa)\n",
        "best_model = models['Logistic Regression']\n",
        "\n",
        "# Működés bemutatása\n",
        "# Függvény a szövegek osztályozására a legjobb modellel\n",
        "def predict_sentiment(text):\n",
        "    cleaned_text = clean_text(text)  # Szöveg tisztítása\n",
        "    text_vec = vectorizer.transform([cleaned_text])  # Szöveg vektorizálása\n",
        "    return best_model.predict(text_vec)  # Előrejelzés készítése\n",
        "\n",
        "# Példa használat\n",
        "example_text = \"This movie was fantastic!\"\n",
        "print(f\"Sentiment prediction for '{example_text}': {predict_sentiment(example_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lMYnNUDByQ5",
        "outputId": "622e0611-3719-4083-cabc-a74cc1cc2f17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.84      0.84       506\n",
            "    positive       0.84      0.83      0.83       494\n",
            "\n",
            "    accuracy                           0.84      1000\n",
            "   macro avg       0.84      0.84      0.84      1000\n",
            "weighted avg       0.84      0.84      0.84      1000\n",
            "\n",
            "Model: Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.81      0.84       506\n",
            "    positive       0.82      0.88      0.85       494\n",
            "\n",
            "    accuracy                           0.85      1000\n",
            "   macro avg       0.85      0.85      0.85      1000\n",
            "weighted avg       0.85      0.85      0.85      1000\n",
            "\n",
            "Sentiment prediction for 'This movie was fantastic!': ['positive']\n"
          ]
        }
      ]
    }
  ]
}